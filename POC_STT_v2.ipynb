{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b439027",
   "metadata": {},
   "source": [
    "TODO :\n",
    "Implémentation\n",
    "Factory pour wake word et STT\n",
    "Dans les configs : pouvoir configurer le micro, les keywords, models wake word, model STT, le temps d'écoute/enregistrement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0546fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %sudo apt-get update\n",
    "# %sudo apt-get install python3-pip python3-dev portaudio19-dev\n",
    "# %pip install sounddevice vosk pvporcupine numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910d62a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %wget https://alphacephei.com/vosk/models/vosk-model-small-fr-0.22.zip\n",
    "# %unzip vosk-model-small-fr-0.22.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc24e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant en écoute... (dites 'Jarvis' pour activer)\n",
      "Wake word détecté ! Parlez maintenant...\n",
      "Texte: stop\n",
      "Arrêt de l'assistant.\n",
      "Wake word détecté ! Parlez maintenant...\n",
      "Texte: stop\n",
      "Arrêt de l'assistant.\n",
      "Wake word détecté ! Parlez maintenant...\n",
      "Texte: shutdown\n",
      "Wake word détecté ! Parlez maintenant...\n",
      "Texte: et speak english\n",
      "Wake word détecté ! Parlez maintenant...\n",
      "Texte: canaille speak english\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 50\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sd.InputStream(\n\u001b[32m     43\u001b[39m     channels=\u001b[32m1\u001b[39m,\n\u001b[32m     44\u001b[39m     samplerate=\u001b[32m16000\u001b[39m,\n\u001b[32m     45\u001b[39m     callback=audio_callback,\n\u001b[32m     46\u001b[39m     blocksize=\u001b[32m512\u001b[39m\n\u001b[32m     47\u001b[39m ):\n\u001b[32m     48\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m     49\u001b[39m         \u001b[38;5;66;03m# Récupère un buffer audio du micro\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m         audio = \u001b[43maudio_q\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m         pcm = (audio.flatten() * \u001b[32m32767\u001b[39m).astype(np.int16)\n\u001b[32m     53\u001b[39m         \u001b[38;5;66;03m# Découpe le buffer en frames pour Porcupine\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\queue.py:171\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    170\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._qsize():\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnot_empty\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m timeout < \u001b[32m0\u001b[39m:\n\u001b[32m    173\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m'\u001b[39m\u001b[33m must be a non-negative number\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py:320\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[32m    319\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m320\u001b[39m         \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    321\u001b[39m         gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    322\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# === Imports ===\n",
    "import sounddevice as sd\n",
    "import queue\n",
    "import json\n",
    "import numpy as np\n",
    "import pvporcupine\n",
    "from vosk import Model, KaldiRecognizer\n",
    "import time\n",
    "\n",
    "# === File audio (buffer) ===\n",
    "audio_q = queue.Queue()\n",
    "\n",
    "def audio_callback(indata, frames, time, status):\n",
    "    \"\"\"Callback pour remplir la file audio avec les données du micro.\"\"\"\n",
    "    if status:\n",
    "        print(status)\n",
    "    audio_q.put(indata.copy())\n",
    "\n",
    "# === Initialisation Porcupine (wake word) ===\n",
    "porcupine = pvporcupine.create(\n",
    "    access_key=\"YTZtqOjD4eEEySY1rj2a3+cn2bNg38bJxzET+jn3SE5jpF9eiTx3hA==\",\n",
    "    model_path=\"wake_word_model/porcupine_params_de.pv\",\n",
    "    keyword_paths=[\"wake_words/glados_de_windows_v3_0_0.ppn\"],\n",
    "    # keywords=[\"jarvis\"]\n",
    ")  # Wake word \"Jarvis\"\n",
    "\n",
    "# === Initialisation Vosk (STT) ===\n",
    "model = Model(\"vosk-model-small-fr-0.22\")\n",
    "recognizer = KaldiRecognizer(model, 16000)\n",
    "\n",
    "def detect_silence(audio, threshold=500):\n",
    "    \"\"\"Détecte le silence dans un tableau numpy d'audio int16.\n",
    "    Retourne True si le niveau moyen est sous le seuil.\"\"\"\n",
    "    energy = np.abs(audio).mean()\n",
    "    return energy < threshold\n",
    "\n",
    "print(\"Assistant en écoute... (dites 'Jarvis' pour activer)\")\n",
    "\n",
    "# === Paramètres d'écoute ===\n",
    "min_silence_len = 2  # Durée minimale de silence (en secondes) pour arrêter l'écoute\n",
    "\n",
    "with sd.InputStream(\n",
    "    channels=1,\n",
    "    samplerate=16000,\n",
    "    callback=audio_callback,\n",
    "    blocksize=512\n",
    "):\n",
    "    while True:\n",
    "        # Récupère un buffer audio du micro\n",
    "        audio = audio_q.get()\n",
    "        pcm = (audio.flatten() * 32767).astype(np.int16)\n",
    "\n",
    "        # Découpe le buffer en frames pour Porcupine\n",
    "        for i in range(0, len(pcm), porcupine.frame_length):\n",
    "            frame = pcm[i:i+porcupine.frame_length]\n",
    "            if len(frame) == porcupine.frame_length:\n",
    "                keyword_index = porcupine.process(frame)\n",
    "                if keyword_index >= 0:\n",
    "                    print(\"Wake word détecté ! Parlez maintenant...\")\n",
    "\n",
    "                    # Vide la file audio pour éviter la redétection immédiate\n",
    "                    while not audio_q.empty():\n",
    "                        try:\n",
    "                            audio_q.get_nowait()\n",
    "                        except Exception:\n",
    "                            break\n",
    "\n",
    "                    frames = []\n",
    "                    start_time = time.time()\n",
    "                    max_duration = 8  # Durée max d'écoute (secondes)\n",
    "                    silence_count = 0\n",
    "                    silence_frames = int((min_silence_len * 16000) // 512)\n",
    "\n",
    "                    # Écoute jusqu'à la fin de phrase (silence ou durée max)\n",
    "                    while True:\n",
    "                        audio = audio_q.get()\n",
    "                        frames.append(audio)\n",
    "                        pcm = (audio.flatten() * 32767).astype(np.int16)\n",
    "                        recognizer.AcceptWaveform(pcm.tobytes())\n",
    "\n",
    "                        if detect_silence(pcm):\n",
    "                            silence_count += 1\n",
    "                        else:\n",
    "                            silence_count = 0\n",
    "\n",
    "                        if silence_count >= silence_frames or (time.time() - start_time > max_duration):\n",
    "                            break\n",
    "\n",
    "                    # Résultat de la reconnaissance vocale\n",
    "                    result = json.loads(recognizer.Result())\n",
    "                    print(\"Texte:\", result.get(\"text\", \"\"))\n",
    "\n",
    "                    break  # Sort du for, donc du buffer courant, et reprend la boucle principale\n",
    "\n",
    "        else:\n",
    "            continue  # Si aucun wake word détecté, on passe au buffer suivant\n",
    "        # Si on a break le for (wake word détecté), on ne traite pas le reste du buffer et on reprend la boucle principale"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
